{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[resource 1](https://github.com/emirhanai/Cryptocurrency-Prediction-with-Artificial-Intelligence/blob/main/Cryptocurrency%20Prediction%20with%20Artificial%20Intelligence.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alpaca_trade_api #.rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "history = datetime.timedelta(days = 50)\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "# https://pypi.org/project/alpaca-trade-api/\n",
    "# alpaca api key, alpaca secret key\n",
    "from alpaca_trade_api.rest import REST, TimeFrame\n",
    "client = REST('PK1H7PEKFTOLZA5S9HHU', 'NF0RkI5lOHLOS1OXFAlT1DsxIPmgJbHHES2iJr8Z')\n",
    "\n",
    "trading_pair= 'BTCUSD'\n",
    "df = client.get_crypto_bars(trading_pair, TimeFrame.Hour, start = date.today() - history, end = date.today()).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df.exchange == 'FTXU']\n",
    "metric = 'close'\n",
    "data = df.filter([metric])\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_perc = .5\n",
    "training_data_len = int(np.ceil( len(df) * split_perc))\n",
    "train_data = df.iloc[:training_data_len]\n",
    "test_data = df.iloc[training_data_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(line1, line2, label1=None, label2=None, title='', lw=2):\n",
    "    fig, ax = plt.subplots(1, figsize=(13, 7))\n",
    "    ax.plot(line1, label=label1, linewidth=lw)\n",
    "    ax.plot(line2, label=label2, linewidth=lw)\n",
    "    ax.set_ylabel('XRP/USDT', fontsize=14)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(loc='best', fontsize=16);\n",
    "line_plot(train_data[metric], test_data[metric], 'train', 'test', title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 5\n",
    "test_size = 0.2\n",
    "zero_base = True\n",
    "lstm_neurons = 50\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "loss = 'mse'\n",
    "dropout = 0.24\n",
    "optimizer = 'adam'\n",
    "\n",
    "def LSTM_model(input_data, output_size, neurons, activ_func='linear',\n",
    "                     dropout=0.2, loss='mse', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    # input_shape = (60, 1)\n",
    "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2]), return_sequences = True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(neurons, return_sequences = True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(neurons))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model\n",
    "np.random.seed(245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "look_back = 72\n",
    "x_train = []\n",
    "y_train = []\n",
    "for price in range(look_back, len(data)):\n",
    "    x_train.append(scaled_data[price - look_back:price, :])\n",
    "    y_train.append(scaled_data[price, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "x_test = []\n",
    "y_test = np.array(scaled_data[training_data_len:, :])\n",
    "for price in range(60, len(test_data)):\n",
    "  x_test.append(test_data[price - look_back:price, 0])\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "\n",
    "model = LSTM_model(\n",
    "    x_train, output_size=1, neurons=lstm_neurons, dropout=dropout, loss=loss,\n",
    "    optimizer=optimizer)\n",
    "# modelfit = model.fit(\n",
    "#     x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "modelfit = model.fit(\n",
    "    x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(modelfit.history['loss'],'r',linewidth=2, label='Training loss')\n",
    "# plt.plot(modelfit.history['val_loss'], 'g',linewidth=2, label='Validation loss')\n",
    "plt.title('LSTM Neural Networks - XRP Model')\n",
    "plt.xlabel('Epochs numbers')\n",
    "plt.ylabel('MSE numbers')\n",
    "plt.show()\n",
    "\n",
    "preds = model.predict(x_test).squeeze()\n",
    "mean_absolute_error(preds, y_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "SCORE_MSE=mean_squared_error(preds, y_test)\n",
    "SCORE_MSE\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score=r2_score(y_test, preds)\n",
    "r2_score*100\n",
    "\n",
    "y_test_true = scaler.inverse_transform(y_test)\n",
    "preds_true = scaler.inverse_transform(preds)\n",
    "line_plot(y_test_true, preds_true, 'actual', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
